# desc2matrix_wcharlist.py user manual

This document explains the up-to-date manual for using `desc2matrix_wcharlist.py`, which converts the description text files generated by the `Makefile` into a structured JSON output containing the traits and corresponding values. The difference between `desc2matrix_py` and this script is that this includes a pre-determined list of traits in the prompt so that model outputs are more or less standardised across species.

## Operation

1. Retrieve the initial list of traits from the charlistfile

2. Retrieve traits from the rest of the species using the list of trait names

The names of traits are fed into the LLM run extracting the traits of the subsequent species. The model is asked to extract the given list of traits, put 'NA' where a given trait is missing in the description, and add any traits that are not in the list but are mentioned in the species description.

## Default prompts

The default prompts are hard-coded in `common_scripts/default_prompts.py`, but can be imported from a text file using the relevant options (see **Arguments**). The prompt must include the following special 'markers':

| Marker | Meaning |
| --- | --- |
| `[DESCRIPTION]` | Plant description text to compile |
| `[CHARACTER_LIST]` | Given list of traits to extract |

### System prompt

See `global_sys_prompt` in `common_scripts/default_prompts.py`.

### Extraction prompt

See `global_prompt` in `common_scripts/default_prompts.py`.

## Arguments

| Argument | Description | Required? | Default value |
| --- | --- | --- | --- |
| `descfile` (positional argument) | Path to the flora description file to transcribe | Yes | |
| `charlistfile` (positional argument) | Path to the list of traits to use | Yes | |
| `--charlistsep` | Character or string to use as separator in `charlistfile` | No | `,` |
| `outputfile` (positional argument) | Path to the output JSON file | Yes | |
| `--desctype` | Name of the 'type' that contains morphological descriptions in the descfile | Yes | |
| `--sysprompt` | Path to a text file containing the system prompt to use | No | See above |
| `--prompt` | Path to a text file containing the prompt to use | No | See above |
| `--silent` | If flag is present, suppress command-line output showing progress | No | `None` |
| `--start` | Order ID (starting from 0) of the species in the descfile to start transcribing from | No | `0` |
| `--spnum` | Number of species to transcribe | No | `None` (transcribe entire file) |
| `--model` | Name of the base LLM to use. Specified LLM must be installed and running at `localhost:11434` | No | `llama3` |
| `--temperature` | Model temperature between 0 and 1. See [here](https://github.com/ollama/ollama/blob/main/docs/modelfile.md) for detailed reference | No | `0.1` |
| `--seed` | Random seed to use for reproducibility. Setting to 0 makes the output random. See [here](https://github.com/ollama/ollama/blob/main/docs/modelfile.md) for detailed reference | No | `1` |
| `--repeatlastn` | Number of tokens(?) the model looks back to prevent repetition. Set to 0 to prevent this behaviour as default. See [here](https://github.com/ollama/ollama/blob/main/docs/modelfile.md) for detailed reference | No | 0 |
| `--numpredict` | Number of tokens for model to generate. See [here](https://github.com/ollama/ollama/blob/main/docs/modelfile.md) for detailed reference | No | `2048` |
| `--numctx` | Size of the context window used to generate the token See [here](https://github.com/ollama/ollama/blob/main/docs/modelfile.md) for detailed reference | No | `4096` |
| `--topk` | Parameter adjusting the degree of 'conservativeness' in the model output. See [here](https://github.com/ollama/ollama/blob/main/docs/modelfile.md) for detailed reference | No | `None` (set to `40` by Ollama) |
| `--topp` | Parameter adjusting the degree of 'conservativeness' in the model output. See [here](https://github.com/ollama/ollama/blob/main/docs/modelfile.md) for detailed reference | No | `None` (set to `0.9` by Ollama) |

## Output

The output is a single JSON object with the following keys:

| Key | Description |
| --- | --- |
| `metadata` | Run metadata |
| `data` | List of JSONs containing transcribed characteristics of each species (see below) |

The `metadata` is itself a JSON containing the following keys:

| Key | Description |
| --- | --- |
| `sys_prompt` | System prompt |
| `prompt` | Prompt used subsequent to `init_prompt` to extract the characteristics |
| `params` | Key-value pairs of parameters used for the model run |
| `mode` | 'Mode' used to generate the output. This is set to `desc2json_wcharlist`. |
| `charlist` | A list of characteristics provided in the prompt for trait extraction |

The `data` list contains JSON objects for every transcribed species, with the following keys:

| Key | Description |
| --- | --- |
| `coreid` | WFO taxon ID of the transcribed species |
| `status` | `success` for successful parse, `invalid_json` for invalid JSON output, `bad_structure` for JSON that's valid but badly structured. |
| `original_description` | The original description imported from WFO |
| `char_json` | List of JSONS containing the transcribed characteristics. Each element is structured as `{"characteristic": name of characteristic, "value": value of characteristic}`. This is `null` if the response failed to parse. |
| `failed_str` | Response string from the LLM that failed to parse to JSON. This is `null` if the response successfully parsed. |